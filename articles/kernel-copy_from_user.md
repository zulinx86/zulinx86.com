---
title: ã€Kernelã€‘copy_to_user() / copy_from_user() / get_user() / put_user()
emoji: "ğŸ§"
type: "tech"
topics: ["linux", "kernel"]
published: true
---

â€» Linux kernel v6.10.1 ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’å…ƒã«èª¿æŸ»ã—ãŸã‚‚ã®ã§ã™ã€‚



# copy_to_user() / copy_from_user() / get_user() / put_user()

- `put_user()`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã¸å˜ä¸€ã®å€¤ (`int`, `char`, `long` ãªã©) ã‚’æ¸¡ã™
- `get_user()`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã‹ã‚‰å˜ä¸€ã®å€¤ã‚’å—ã‘å–ã‚‹
- `copy_to_user()`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã«ä»»æ„ã®é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
- `copy_from_user()`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã‹ã‚‰ä»»æ„ã®é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹

https://www.kernel.org/doc/html/latest/kernel-hacking/hacking.html#copy-to-user-copy-from-user-get-user-put-user

> `copy_to_user()` / `copy_from_user()` / `get_user()` / `put_user()`
>
> Defined in `include/linux/uaccess.h` / `asm/uaccess.h`
> 
> [SLEEPS]
> 
> `put_user()` and `get_user()` are used to get and put single values (such as an int, char, or long) from and to userspace. A pointer into userspace should never be simply dereferenced: data should be copied using these routines. Both return -EFAULT or 0.
> 
> copy_to_user() and copy_from_user() are more general: they copy an arbitrary amount of data to and from userspace.
>
> Warning:
> Unlike put_user() and get_user(), they return the amount of uncopied data (ie. 0 still means success).
>
> [Yes, this objectionable interface makes me cringe. The flamewar comes up every year or so. --RR.]
>
> The functions may sleep implicitly. This should never be called outside user context (it makes no sense), with interrupts disabled, or a spinlock held.



# x86


## [`put_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/uaccess.h#L191)

å‰è¿°ã®é€šã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã«å˜ä¸€ã®å€¤ã‚’æ›¸ãè¾¼ã‚€é–¢æ•°ã§ã‚ã‚‹ã€‚

ã¾ãŸã€ã‚³ãƒ¡ãƒ³ãƒˆã«ã‚ã‚‹é€šã‚Šã€ãƒšãƒ¼ã‚¸ãƒ•ã‚©ãƒ«ãƒˆãŒæœ‰åŠ¹ãªå ´åˆã¯ã€é–¢æ•°ãŒã‚¹ãƒªãƒ¼ãƒ—ã™ã‚‹å ´åˆãŒã‚ã‚‹ã€‚

```c
/**
 * put_user - Write a simple value into user space.
 * @x:   Value to copy to user space.
 * @ptr: Destination address, in user space.
 *
 * Context: User context only. This function may sleep if pagefaults are
 *          enabled.
 *
 * This macro copies a single simple value from kernel space to user
 * space.  It supports simple types like char and int, but not larger
 * data types like structures or arrays.
 *
 * @ptr must have pointer-to-simple-variable type, and @x must be assignable
 * to the result of dereferencing @ptr.
 *
 * Return: zero on success, or -EFAULT on error.
 */
#define put_user(x, ptr) ({ might_fault(); do_put_user_call(put_user,x,ptr); })
```

`might_fault()` ã¯ã€ã‚„ã‚„è¤‡é›‘ãã†ã ã£ãŸã®ã§ã€æœ¬è¨˜äº‹ã§ã¯å‰²æ„›ã—ã¾ã™ã€‚å¾Œæ—¥åˆ¥ã®è¨˜äº‹ã«ã™ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚Šã§ã™ã€‚

### [`do_put_user_call()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/uaccess.h#L170)

çµè«–ã ã‘ã‚’ã„ã†ã¨ã€ã‚µã‚¤ã‚ºã«å¿œã˜ã¦ `__put_user_1()`, `__put_user_2()`, `__put_user_4()`, `__put_user_8()` ã®ã„ãšã‚Œã‹ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ã€‚

ã‚‚ã†å°‘ã—ã ã‘å…·ä½“çš„ã«ã‚¢ã‚»ãƒ³ãƒ–ãƒªã®å‘¼ã³å‡ºã—éƒ¨åˆ†ã‚’è¦‹ã‚‹ã€‚
- è¿”ã‚Šå€¤ `__ret_pu` ã¯ RCX ãƒ¬ã‚¸ã‚¹ã‚¿ã«å‡ºåŠ›ã•ã‚Œã‚‹ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã®ãƒã‚¤ãƒ³ã‚¿ `__ptr_pu` ã¯ã€`__ret_pu` ã¨åŒæ§˜ã« RCX ãƒ¬ã‚¸ã‚¹ã‚¿ã«ä¿æŒã™ã‚‹ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã«æ¸¡ã™å€¤ `__val_pu` ã¯ã€RAX ãƒ¬ã‚¸ã‚¹ã‚¿ã«ä¿æŒã™ã‚‹ã€‚

```c
/*
 * ptr must be evaluated and assigned to the temporary __ptr_pu before
 * the assignment of x to __val_pu, to avoid any function calls
 * involved in the ptr expression (possibly implicitly generated due
 * to KASAN) from clobbering %ax.
 */
#define do_put_user_call(fn,x,ptr)					\
({									\
	int __ret_pu;							\
	void __user *__ptr_pu;						\
	register __typeof__(*(ptr)) __val_pu asm("%"_ASM_AX);		\
	__typeof__(*(ptr)) __x = (x); /* eval x once */			\
	__typeof__(ptr) __ptr = (ptr); /* eval ptr once */		\
	__chk_user_ptr(__ptr);						\
	__ptr_pu = __ptr;						\
	__val_pu = __x;							\
	asm volatile("call __" #fn "_%c[size]"				\
		     : "=c" (__ret_pu),					\
			ASM_CALL_CONSTRAINT				\
		     : "0" (__ptr_pu),					\
		       "r" (__val_pu),					\
		       [size] "i" (sizeof(*(ptr)))			\
		     :"ebx");						\
	instrument_put_user(__x, __ptr, sizeof(*(ptr)));		\
	__builtin_expect(__ret_pu, 0);					\
})
```

### [`__put_user_1`, `__put_user_2`, `__put_user_4`, `__put_user_8`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/lib/putuser.S#L47)

`check_range` ã«ã¤ã„ã¦ã¯å¾Œè¿°ã€‚

[STAC å‘½ä»¤](https://www.felixcloutier.com/x86/stac) ã¯ EFLAGS ãƒ¬ã‚¸ã‚¹ã‚¿ã® AC ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆã™ã‚‹ã€‚ã“ã‚Œã¯ã‚«ãƒ¼ãƒãƒ«ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã®ãƒ¡ãƒ¢ãƒªã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã‚’è¨±å¯ã™ã‚‹ãŸã‚ã®å‘½ä»¤ã§ã‚ã‚‹ã€‚[CLAC å‘½ä»¤](https://www.felixcloutier.com/x86/clac) ã¯ã€é€†ã« EFLAGS ãƒ¬ã‚¸ã‚¹ã‚¿ã® AC ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚

å‰è¿°ã®é€šã‚Šã€RCX ãƒ¬ã‚¸ã‚¹ã‚¿ã«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã®ãƒã‚¤ãƒ³ã‚¿ã€RAX ãƒ¬ã‚¸ã‚¹ã‚¿ã«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã«æ¸¡ã™å€¤ãŒã‚»ãƒƒãƒˆã•ã‚Œã¦ã„ã‚‹ã€‚
`movb %al,(%_ASM_CX)` ç­‰ã®å ´æ‰€ã§å®Ÿéš›ã«å€¤ãŒã‚³ãƒ”ãƒ¼ã•ã‚Œã¦ã„ã‚‹ã€‚

ãã®å¾Œ `xor %ecx,%ecx` ã‚’å®Ÿè¡Œã—ã€ECX ãƒ¬ã‚¸ã‚¹ã‚¿ã‚’ 0 ã«ã‚»ãƒƒãƒˆã—ã€è¿”ã‚Šå€¤ã¨ã—ã¦ `__ret_pu` ã«ã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã€‚

```c
SYM_FUNC_START(__put_user_1)
	check_range size=1
	ASM_STAC
1:	movb %al,(%_ASM_CX)
	xor %ecx,%ecx
	ASM_CLAC
	RET
SYM_FUNC_END(__put_user_1)
EXPORT_SYMBOL(__put_user_1)
```
```c
SYM_FUNC_START(__put_user_2)
	check_range size=2
	ASM_STAC
3:	movw %ax,(%_ASM_CX)
	xor %ecx,%ecx
	ASM_CLAC
	RET
SYM_FUNC_END(__put_user_2)
EXPORT_SYMBOL(__put_user_2)
```
```c
SYM_FUNC_START(__put_user_4)
	check_range size=4
	ASM_STAC
5:	movl %eax,(%_ASM_CX)
	xor %ecx,%ecx
	ASM_CLAC
	RET
SYM_FUNC_END(__put_user_4)
EXPORT_SYMBOL(__put_user_4)
```
```c
SYM_FUNC_START(__put_user_8)
	check_range size=8
	ASM_STAC
7:	mov %_ASM_AX,(%_ASM_CX)
#ifdef CONFIG_X86_32
8:	movl %edx,4(%_ASM_CX)
#endif
	xor %ecx,%ecx
	ASM_CLAC
	RET
SYM_FUNC_END(__put_user_8)
EXPORT_SYMBOL(__put_user_8)
```


### [`check_range`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/lib/putuser.S#L35)

å‰è¿°ã®é€šã‚Šã€RCX ã«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹ãƒã‚¤ãƒ³ã‚¿ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå‰æã¨ãªã‚‹ã€‚
RBX ã«ä¸€æ—¦ç§»å‹•ã—ã€æœ€ä¸Šä½ãƒ“ãƒƒãƒˆã‚’ä½¿ã£ãŸ 64-bit ã®ãƒã‚¹ã‚¯ã‚’ä½œæˆã—ã€OR ã‚’ã¨ã£ã¦ã„ã‚‹ã€‚
ã—ãŸãŒã£ã¦ã€æœ€ä¸Šä½ãƒ“ãƒƒãƒˆãŒ 0 ã®å ´åˆã€ä¸ãˆã‚‰ã‚ŒãŸãƒã‚¤ãƒ³ã‚¿ãã®ã¾ã¾ãŒè¿”ã•ã‚Œã€ãã†ã§ãªã„å ´åˆã¯ `~0` ã®ãƒã‚¤ãƒ³ã‚¿ãŒè¿”ã•ã‚Œã‚‹ã€‚

```c
.macro check_range size:req
.if IS_ENABLED(CONFIG_X86_64)
	mov %rcx, %rbx
	sar $63, %rbx
	or %rbx, %rcx
.else
	cmp $TASK_SIZE_MAX-\size+1, %ecx
	jae .Lbad_put_user
.endif
.endm
```

ä»¥ä¸‹ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ä¸ãˆã‚‰ã‚ŒãŸãƒã‚¤ãƒ³ã‚¿ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹ã®ã‚‚ã®ã§ã‚ã‚Œã°ã€ãã®ã¾ã¾ã®å€¤ã‚’è¿”ã—ã€ã‚«ãƒ¼ãƒãƒ«ã‚¹ãƒšãƒ¼ã‚¹ã§ã‚ã‚Œã° unused hole ã‚’ç¤ºã™ `~0` ã‚’è¿”ã™ã“ã¨ã«ãªã‚‹ã€‚

https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt

```
========================================================================================================================
    Start addr    |   Offset   |     End addr     |  Size   | VM area description
========================================================================================================================
                  |            |                  |         |
 0000000000000000 |    0       | 00007fffffffffff |  128 TB | user-space virtual memory, different per mm
__________________|____________|__________________|_________|___________________________________________________________
                  |            |                  |         |
 0000800000000000 | +128    TB | ffff7fffffffffff | ~16M TB | ... huge, almost 64 bits wide hole of non-canonical
                  |            |                  |         |     virtual memory addresses up to the -128 TB
                  |            |                  |         |     starting offset of kernel mappings.
__________________|____________|__________________|_________|___________________________________________________________
                                                            |
                                                            | Kernel-space virtual memory, shared between all processes:
____________________________________________________________|___________________________________________________________
                  |            |                  |         |
 ffff800000000000 | -128    TB | ffff87ffffffffff |    8 TB | ... guard hole, also reserved for hypervisor
 ffff880000000000 | -120    TB | ffff887fffffffff |  0.5 TB | LDT remap for PTI
 ffff888000000000 | -119.5  TB | ffffc87fffffffff |   64 TB | direct mapping of all physical memory (page_offset_base)
 ffffc88000000000 |  -55.5  TB | ffffc8ffffffffff |  0.5 TB | ... unused hole
 ffffc90000000000 |  -55    TB | ffffe8ffffffffff |   32 TB | vmalloc/ioremap space (vmalloc_base)
 ffffe90000000000 |  -23    TB | ffffe9ffffffffff |    1 TB | ... unused hole
 ffffea0000000000 |  -22    TB | ffffeaffffffffff |    1 TB | virtual memory map (vmemmap_base)
 ffffeb0000000000 |  -21    TB | ffffebffffffffff |    1 TB | ... unused hole
 ffffec0000000000 |  -20    TB | fffffbffffffffff |   16 TB | KASAN shadow memory
__________________|____________|__________________|_________|____________________________________________________________
                                                            |
                                                            | Identical layout to the 56-bit one from here on:
____________________________________________________________|____________________________________________________________
                  |            |                  |         |
 fffffc0000000000 |   -4    TB | fffffdffffffffff |    2 TB | ... unused hole
                  |            |                  |         | vaddr_end for KASLR
 fffffe0000000000 |   -2    TB | fffffe7fffffffff |  0.5 TB | cpu_entry_area mapping
 fffffe8000000000 |   -1.5  TB | fffffeffffffffff |  0.5 TB | ... unused hole
 ffffff0000000000 |   -1    TB | ffffff7fffffffff |  0.5 TB | %esp fixup stacks
 ffffff8000000000 | -512    GB | ffffffeeffffffff |  444 GB | ... unused hole
 ffffffef00000000 |  -68    GB | fffffffeffffffff |   64 GB | EFI region mapping space
 ffffffff00000000 |   -4    GB | ffffffff7fffffff |    2 GB | ... unused hole
 ffffffff80000000 |   -2    GB | ffffffff9fffffff |  512 MB | kernel text mapping, mapped to physical address 0
 ffffffff80000000 |-2048    MB |                  |         |
 ffffffffa0000000 |-1536    MB | fffffffffeffffff | 1520 MB | module mapping space
 ffffffffff000000 |  -16    MB |                  |         |
    FIXADDR_START | ~-11    MB | ffffffffff5fffff | ~0.5 MB | kernel-internal fixmap range, variable size and offset
 ffffffffff600000 |  -10    MB | ffffffffff600fff |    4 kB | legacy vsyscall ABI
 ffffffffffe00000 |   -2    MB | ffffffffffffffff |    2 MB | ... unused hole
__________________|____________|__________________|_________|___________________________________________________________
```

[ã“ã®ãƒ‘ãƒƒãƒ](https://lore.kernel.org/all/20230312112612.31869-2-kirill.shutemov@linux.intel.com/)ã‚‚ä½µã›ã¦èª­ã‚€ã¨è‰¯ã„ã€‚


## [`get_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/uaccess.h#L108)

```c
/**
 * get_user - Get a simple variable from user space.
 * @x:   Variable to store result.
 * @ptr: Source address, in user space.
 *
 * Context: User context only. This function may sleep if pagefaults are
 *          enabled.
 *
 * This macro copies a single simple variable from user space to kernel
 * space.  It supports simple types like char and int, but not larger
 * data types like structures or arrays.
 *
 * @ptr must have pointer-to-simple-variable type, and the result of
 * dereferencing @ptr must be assignable to @x without a cast.
 *
 * Return: zero on success, or -EFAULT on error.
 * On error, the variable @x is set to zero.
 */
#define get_user(x,ptr) ({ might_fault(); do_get_user_call(get_user,x,ptr); })
```

### [`do_get_user_call()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/uaccess.h#L76)

`get_user()` ã‹ã‚‰ã‚‚ `__get_user()` ã‹ã‚‰ã‚‚ä½¿ã‚ã‚Œã‚‹é–¢æ•°ã¨ã®ã“ã¨ã€‚
çµæœçš„ã«ã¯ã‚µã‚¤ã‚ºã«å¿œã˜ãŸ `__get_user_<size>()` ã‚’å‘¼ã³å‡ºã™ã€‚

ã‚¢ã‚»ãƒ³ãƒ–ãƒªã®å‘¼ã³å‡ºã—éƒ¨åˆ†ã‚’ã‚‚ã†å°‘ã—è¦‹ã‚‹ã€‚
- è¿”ã‚Šå€¤ `__ret_gu` ã¯ã€RAX ãƒ¬ã‚¸ã‚¹ã‚¿ã«å‡ºåŠ›ã•ã‚Œã‚‹ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å—ã‘å–ã‚‹å€¤ `__val_gu` ã¯ã€RDX ãƒ¬ã‚¸ã‚¹ã‚¿ã«å‡ºåŠ›ã•ã‚Œã‚‹ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã®ãƒã‚¤ãƒ³ã‚¿ `ptr` ã¯ã€`__ret_gu` ã¨åŒæ§˜ã« RAX ãƒ¬ã‚¸ã‚¹ã‚¿ã«ä¿æŒã™ã‚‹ã€‚

```c
/*
 * This is used for both get_user() and __get_user() to expand to
 * the proper special function call that has odd calling conventions
 * due to returning both a value and an error, and that depends on
 * the size of the pointer passed in.
 *
 * Careful: we have to cast the result to the type of the pointer
 * for sign reasons.
 *
 * The use of _ASM_DX as the register specifier is a bit of a
 * simplification, as gcc only cares about it as the starting point
 * and not size: for a 64-bit value it will use %ecx:%edx on 32 bits
 * (%ecx being the next register in gcc's x86 register sequence), and
 * %rdx on 64 bits.
 *
 * Clang/LLVM cares about the size of the register, but still wants
 * the base register for something that ends up being a pair.
 */
#define do_get_user_call(fn,x,ptr)					\
({									\
	int __ret_gu;							\
	register __inttype(*(ptr)) __val_gu asm("%"_ASM_DX);		\
	__chk_user_ptr(ptr);						\
	asm volatile("call __" #fn "_%c[size]"				\
		     : "=a" (__ret_gu), "=r" (__val_gu),		\
			ASM_CALL_CONSTRAINT				\
		     : "0" (ptr), [size] "i" (sizeof(*(ptr))));		\
	instrument_get_user(__val_gu);					\
	(x) = (__force __typeof__(*(ptr))) __val_gu;			\
	__builtin_expect(__ret_gu, 0);					\
})
```

### [`__get_user_1`, `__get_user_2`, `__get_user_4`, `__get_user_8`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/lib/getuser.S#L58)

`check_range` ã«ã¤ã„ã¦ã¯å¾Œè¿°ã€‚

STAC å‘½ä»¤ã¨ CLAC å‘½ä»¤ã¯å‰è¿°ã®é€šã‚Šã€‚

å‰è¿°ã®é€šã‚Šã€RAX ãƒ¬ã‚¸ã‚¹ã‚¿ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã®ãƒã‚¤ãƒ³ã‚¿ã€RDX ãƒ¬ã‚¸ã‚¹ã‚¿ã«èª­ã¿è¾¼ã‚“ã å€¤ã‚’å…¥ã‚Œã‚‹ã€‚
`movzbl (%_ASM_AX),%edx` ã®éƒ¨åˆ†ãŒå€¤ã®èª­ã¿è¾¼ã‚“ã§ã„ã‚‹éƒ¨åˆ†ã§ã‚ã‚‹ã€‚

æœ€å¾Œã«è¿”ã‚Šå€¤ã§ã‚ã‚‹ EAX ãƒ¬ã‚¸ã‚¹ã‚¿ã‚’ 0 ã«ã‚»ãƒƒãƒˆã—ã¦ãƒªã‚¿ãƒ¼ãƒ³ã™ã‚‹ã€‚

```c
	.text
SYM_FUNC_START(__get_user_1)
	check_range size=1
	ASM_STAC
1:	movzbl (%_ASM_AX),%edx
	xor %eax,%eax
	ASM_CLAC
	RET
SYM_FUNC_END(__get_user_1)
EXPORT_SYMBOL(__get_user_1)

SYM_FUNC_START(__get_user_2)
	check_range size=2
	ASM_STAC
2:	movzwl (%_ASM_AX),%edx
	xor %eax,%eax
	ASM_CLAC
	RET
SYM_FUNC_END(__get_user_2)
EXPORT_SYMBOL(__get_user_2)

SYM_FUNC_START(__get_user_4)
	check_range size=4
	ASM_STAC
3:	movl (%_ASM_AX),%edx
	xor %eax,%eax
	ASM_CLAC
	RET
SYM_FUNC_END(__get_user_4)
EXPORT_SYMBOL(__get_user_4)

SYM_FUNC_START(__get_user_8)
	check_range size=8
	ASM_STAC
#ifdef CONFIG_X86_64
4:	movq (%_ASM_AX),%rdx
#else
4:	movl (%_ASM_AX),%edx
5:	movl 4(%_ASM_AX),%ecx
#endif
	xor %eax,%eax
	ASM_CLAC
	RET
SYM_FUNC_END(__get_user_8)
EXPORT_SYMBOL(__get_user_8)
```

### [`check_range`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/lib/getuser.S#L40)

64-bit ã®å ´åˆã¯ã€`put_user()` ã¨åŒã˜ãƒã‚¹ã‚­ãƒ³ã‚°ã‚’ã—ã¦ã„ã‚‹ã€‚

32-bit ã®å ´åˆã¯ã€æœ€ä¸Šä½ãƒ“ãƒƒãƒˆã‚’ä½¿ã£ãŸãƒã‚¹ã‚­ãƒ³ã‚°ã¯ä½¿ãˆãšã€`array_index_mask_nospec()` ã¨åŒã˜ Bounds Clipping ã‚’ä½¿ã£ã¦ã„ã‚‹ã€‚(è©³ç´°ã¯å‰²æ„›)

```c
.macro check_range size:req
.if IS_ENABLED(CONFIG_X86_64)
	mov %rax, %rdx
	sar $63, %rdx
	or %rdx, %rax
.else
	cmp $TASK_SIZE_MAX-\size+1, %eax
.if \size != 8
	jae .Lbad_get_user
.else
	jae .Lbad_get_user_8
.endif
	sbb %edx, %edx		/* array_index_mask_nospec() */
	and %edx, %eax
.endif
.endm
```


## [`copy_to_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/include/linux/uaccess.h#L188)

```c
static __always_inline unsigned long __must_check
copy_to_user(void __user *to, const void *from, unsigned long n)
{
	if (check_copy_size(from, n, true))
		n = _copy_to_user(to, from, n);
	return n;
}
```

### [`check_copy_size()`](https://elixir.bootlin.com/linux/v6.10.1/source/include/linux/thread_info.h#L237)

ä¸€æ—¦ã€ã“ã®è¨˜äº‹ã§ã¯æ·±æ˜ã‚Šã—ãªã„ã€‚åŸºæœ¬çš„ã«ã¯ true ãŒè¿”ã‚‹ã‚‚ã®ã¨æƒ³å®šã€‚

```c
static __always_inline __must_check bool
check_copy_size(const void *addr, size_t bytes, bool is_source)
{
	int sz = __builtin_object_size(addr, 0);
	if (unlikely(sz >= 0 && sz < bytes)) {
		if (!__builtin_constant_p(bytes))
			copy_overflow(sz, bytes);
		else if (is_source)
			__bad_copy_from();
		else
			__bad_copy_to();
		return false;
	}
	if (WARN_ON_ONCE(bytes > INT_MAX))
		return false;
	check_object_size(addr, bytes, is_source);
	return true;
}
```

### `_copy_to_user()`

ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨é€šå¸¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã€‚é•ã„ã¨ã—ã¦ã¯ã€`static inline __must_check` ãŒã¤ã„ã¦ã‚‹ãã‚‰ã„ã€‚

`should_fail_usercopy()` ã¯ã€ã–ã£ã¨ã¿ãŸæ„Ÿã˜ã¯æ„å›³çš„ã«ã‚³ãƒ”ãƒ¼ã‚’å¤±æ•—ã•ã›ãŸã„æ™‚ã«ä½¿ã†ã‚‚ã®ã£ã½ã„ã®ã§ã‚¹ãƒ«ãƒ¼ã€‚

`access_ok()` ã«ã¤ã„ã¦ã¯ã€[ã“ã®è¨˜äº‹](https://zenn.dev/zulinx86/articles/kernel-access_ok)ã‚’å‚ç…§ã€‚

`instrument_copy_to_user()` ã¯ instrumentation é–¢é€£ãªã®ã§ä¸€æ—¦ã‚¹ãƒ«ãƒ¼ã€‚

[https://elixir.bootlin.com/linux/v6.10.1/source/include/linux/uaccess.h#L163](https://elixir.bootlin.com/linux/v6.10.1/source/include/linux/uaccess.h#L163)
```c
#ifdef INLINE_COPY_TO_USER
static inline __must_check unsigned long
_copy_to_user(void __user *to, const void *from, unsigned long n)
{
	might_fault();
	if (should_fail_usercopy())
		return n;
	if (access_ok(to, n)) {
		instrument_copy_to_user(to, from, n);
		n = raw_copy_to_user(to, from, n);
	}
	return n;
}
#else
extern __must_check unsigned long
_copy_to_user(void __user *, const void *, unsigned long);
#endif
```

[https://elixir.bootlin.com/linux/v6.10.1/source/lib/usercopy.c#L39](https://elixir.bootlin.com/linux/v6.10.1/source/lib/usercopy.c#L39)
```c
#ifndef INLINE_COPY_TO_USER
unsigned long _copy_to_user(void __user *to, const void *from, unsigned long n)
{
	might_fault();
	if (should_fail_usercopy())
		return n;
	if (likely(access_ok(to, n))) {
		instrument_copy_to_user(to, from, n);
		n = raw_copy_to_user(to, from, n);
	}
	return n;
}
EXPORT_SYMBOL(_copy_to_user);
#endif
```

### [`raw_copy_to_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/uaccess_64.h#L129)

`copy_user_generic()` ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã€‚

```c
static __always_inline __must_check unsigned long
raw_copy_to_user(void __user *dst, const void *src, unsigned long size)
{
	return copy_user_generic((__force void *)dst, src, size);
}
```

### [`copy_user_generic()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/uaccess_64.h#L103)

æœ€åˆã¨æœ€å¾Œã« `stac()` ã¨ `clac()` ã‚’èª­ã‚“ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æœ‰åŠ¹ã«ã—ã¦ã„ã‚‹ã€‚

FSRM (Fast Short REP MOV) ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹å ´åˆã¯ `rep movs` ã‚’ä½¿ã„ã€ãã†ã§ãªã„å ´åˆã¯ [`rep_movs_alternative`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/lib/copy_user_64.S#L32) ã‚’ä½¿ã£ã¦ã„ã‚‹ã€‚

FSRM ãŒåˆ©ç”¨å¯èƒ½ã¨ã“ã“ã§ã¯æƒ³å®šã™ã‚‹ã“ã¨ã«ã™ã‚‹ã€‚

ã‚¢ã‚»ãƒ³ãƒ–ãƒªã®éƒ¨åˆ†ã‚’ã¡ã‚‡ã£ã¨ç¢ºèªã€‚
- `len` ã¯ RCX ãƒ¬ã‚¸ã‚¹ã‚¿ã«ã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã€‚
- `to` ã¯ DI ãƒ¬ã‚¸ã‚¹ã‚¿ã«ã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã€‚
- `from` ã¯ SI ãƒ¬ã‚¸ã‚¹ã‚¿ã«ã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã€‚

[REP å‘½ä»¤](https://www.felixcloutier.com/x86/rep:repe:repz:repne:repnz) ã¯ã€RCX = 0 ã«ãªã‚‹ã¾ã§ãƒ«ãƒ¼ãƒ—ã™ã‚‹ã€‚
[MOVSB å‘½ä»¤](https://www.felixcloutier.com/x86/movs:movsb:movsw:movsd:movsq) ã¯ã€RSI ã‹ã‚‰ RDI ã¸ï¼‘ãƒã‚¤ãƒˆã‚³ãƒ”ãƒ¼ã™ã‚‹ã€‚

```c
static __always_inline __must_check unsigned long
copy_user_generic(void *to, const void *from, unsigned long len)
{
	stac();
	/*
	 * If CPU has FSRM feature, use 'rep movs'.
	 * Otherwise, use rep_movs_alternative.
	 */
	asm volatile(
		"1:\n\t"
		ALTERNATIVE("rep movsb",
			    "call rep_movs_alternative", ALT_NOT(X86_FEATURE_FSRM))
		"2:\n"
		_ASM_EXTABLE_UA(1b, 2b)
		:"+c" (len), "+D" (to), "+S" (from), ASM_CALL_CONSTRAINT
		: : "memory", "rax");
	clac();
	return len;
}
```


## [`copy_from_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/include/linux/uaccess.h#L180)

```c
static __always_inline unsigned long __must_check
copy_from_user(void *to, const void __user *from, unsigned long n)
{
	if (check_copy_size(to, n, false))
		n = _copy_from_user(to, from, n);
	return n;
}
```

### `_copy_from_user()`

`_copy_to_user()` ã¨åŒæ§˜ã«ã€ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨é€šå¸¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã€‚
ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã¯ã€speculation barrier ãŒãªã„ã€‚

`raw_copy_from_user()` ãŒæœ¬ä½“ã§ã€ã‚‚ã—å¤±æ•—ã—ãŸå ´åˆã¯ `memset()` ã§ 0 ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ã€‚

ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³

[https://elixir.bootlin.com/linux/v6.10.1/source/include/linux/uaccess.h#L143](https://elixir.bootlin.com/linux/v6.10.1/source/include/linux/uaccess.h#L143)
```c
#ifdef INLINE_COPY_FROM_USER
static inline __must_check unsigned long
_copy_from_user(void *to, const void __user *from, unsigned long n)
{
	unsigned long res = n;
	might_fault();
	if (!should_fail_usercopy() && likely(access_ok(from, n))) {
		instrument_copy_from_user_before(to, from, n);
		res = raw_copy_from_user(to, from, n);
		instrument_copy_from_user_after(to, from, n, res);
	}
	if (unlikely(res))
		memset(to + (n - res), 0, res);
	return res;
}
#else
extern __must_check unsigned long
_copy_from_user(void *, const void __user *, unsigned long);
#endif
```

é€šå¸¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³

[https://elixir.bootlin.com/linux/v6.10.1/source/lib/usercopy.c#L16](https://elixir.bootlin.com/linux/v6.10.1/source/lib/usercopy.c#L16)
```c
#ifndef INLINE_COPY_FROM_USER
unsigned long _copy_from_user(void *to, const void __user *from, unsigned long n)
{
	unsigned long res = n;
	might_fault();
	if (!should_fail_usercopy() && likely(access_ok(from, n))) {
		/*
		 * Ensure that bad access_ok() speculation will not
		 * lead to nasty side effects *after* the copy is
		 * finished:
		 */
		barrier_nospec();
		instrument_copy_from_user_before(to, from, n);
		res = raw_copy_from_user(to, from, n);
		instrument_copy_from_user_after(to, from, n, res);
	}
	if (unlikely(res))
		memset(to + (n - res), 0, res);
	return res;
}
EXPORT_SYMBOL(_copy_from_user);
#endif
```

### [`barrier_nospec()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/barrier.h#L48)

LFENCE å‘½ä»¤ãŒãƒãƒªã‚¢ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚

```c
/* Prevent speculative execution past this barrier. */
#define barrier_nospec() alternative("", "lfence", X86_FEATURE_LFENCE_RDTSC)
```

### [`raw_copy_from_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/x86/include/asm/uaccess_64.h#L123)

`raw_copy_to_user()` ã¨åŒæ§˜ã« `copy_user_generic()` ã‚’å‘¼ã³å‡ºã™ã€‚

```c
static __always_inline __must_check unsigned long
raw_copy_from_user(void *dst, const void __user *src, unsigned long size)
{
	return copy_user_generic(dst, (__force void *)src, size);
}
```


# arm64


## [`put_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L340)

`__put_user` ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã€‚

```c
#define put_user	__put_user
```

### [`__put_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L333)

```c
#define __put_user(x, ptr)						\
({									\
	int __pu_err = 0;						\
	__put_user_error((x), (ptr), __pu_err);				\
	__pu_err;							\
})
```

### [`__put_user_error()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L321)

`access_ok()` ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã®ãƒã‚¤ãƒ³ã‚¿ã‹ãƒã‚§ãƒƒã‚¯ã—ãŸå¾Œã«ã€`uaccess_mask_ptr()` ã§ãƒã‚¤ãƒ³ã‚¿ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã‚’è¡Œã†ã€‚

```c
#define __put_user_error(x, ptr, err)					\
do {									\
	__typeof__(*(ptr)) __user *__p = (ptr);				\
	might_fault();							\
	if (access_ok(__p, sizeof(*__p))) {				\
		__p = uaccess_mask_ptr(__p);				\
		__raw_put_user((x), __p, (err));			\
	} else	{							\
		(err) = -EFAULT;					\
	}								\
} while (0)
```

### [`uaccess_mask_ptr()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L164)

[BIC å‘½ä»¤](https://developer.arm.com/documentation/ddi0602/2024-06/Base-Instructions/BIC--shifted-register---Bitwise-bit-clear--shifted-register--)ã¯ã€ä»¥ä¸‹ã®æ“ä½œã‚’ã™ã‚‹å‘½ä»¤ã§ã‚ã‚‹ã€‚

> BIC <Xd>, <Xn>, <Xm>{, <shift> #<amount>}

> Operation
> ```
> constant bits(datasize) operand1 = X[n, datasize];
> constant bits(datasize) operand2 = ShiftReg(m, shift_type, shift_amount, datasize);
> 
> X[d, datasize] = operand1 AND NOT(operand2);
> ```

ä»¥ä¸‹ã®ãƒ‘ãƒƒãƒã«è¨˜è¼‰ã®é€šã‚Šã€bit 55 ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¦ã‚Œã° TTBR0 VA ãƒ¬ãƒ³ã‚¸ã€bit 55 ãŒã‚»ãƒƒãƒˆã•ã‚Œã¦ã‚Œã° TTBR1 VA ãƒ¬ãƒ³ã‚¸ã¨ãªã‚‹ã€‚

https://lore.kernel.org/all/20220922151053.3520750-1-mark.rutland@arm.com/

> Regardless of the configured VA size or whether TBI is in use, the
> address space can be divided into three ranges:
> 
> * The TTBR0 VA range, for which any valid pointer has bit 55 *clear*,
>   and any non-tag bits [63-56] must match bit 55 (i.e. must be clear).
> 
> * The TTBR1 VA range, for which any valid pointer has bit 55 *set*, and
>   any non-tag bits [63-56] must match bit 55 (i.e. must be set).
> 
> * The gap between the TTBR0 and TTBR1 ranges, where bit 55 may be set or
>   clear, but any access will result in a fault.

[TTBR0 (Translation Table Base Register 0)](https://developer.arm.com/documentation/100442/0100/register-descriptions/aarch32-system-registers/ttbr0--translation-table-base-register-0) ã¨ [TTBR1 (Translation Table Base Register 1)](https://developer.arm.com/documentation/100442/0100/register-descriptions/aarch32-system-registers/ttbr1--translation-table-base-register-1) ã¯ã€Translation Table ã®ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å…¥ã‚Œã‚‹ãƒ¬ã‚¸ã‚¹ã‚¿ã§ã‚ã‚‹ã€‚

ã—ãŸãŒã£ã¦ã€`uaccess_mask_ptr()` ã¯ bit 55 ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã“ã¨ã§ã€å¼·åˆ¶çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã«ã—ã¦ã„ã‚‹ã€‚

```c
/*
 * Sanitize a uaccess pointer such that it cannot reach any kernel address.
 *
 * Clearing bit 55 ensures the pointer cannot address any portion of the TTBR1
 * address range (i.e. any kernel address), and either the pointer falls within
 * the TTBR0 address range or must cause a fault.
 */
#define uaccess_mask_ptr(ptr) (__typeof__(ptr))__uaccess_mask_ptr(ptr)
static inline void __user *__uaccess_mask_ptr(const void __user *ptr)
{
	void __user *safe_ptr;

	asm volatile(
	"	bic	%0, %1, %2\n"
	: "=r" (safe_ptr)
	: "r" (ptr),
	  "i" (BIT(55))
	);

	return safe_ptr;
}
```

### [`__raw_put_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L310)

`uaccess_ttbr0_enable()` ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ç©ºé–“ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æœ‰åŠ¹ã«ã—ã€`uaccess_ttbr0_disable()` ã§ç„¡åŠ¹ã«ã™ã‚‹ã€‚(è©³ç´°ã¯ä¸€æ—¦å‰²æ„›)

```c
/*
 * We must not call into the scheduler between uaccess_ttbr0_enable() and
 * uaccess_ttbr0_disable(). As `x` and `ptr` could contain blocking functions,
 * we must evaluate these outside of the critical section.
 */
#define __raw_put_user(x, ptr, err)					\
do {									\
	__typeof__(*(ptr)) __user *__rpu_ptr = (ptr);			\
	__typeof__(*(ptr)) __rpu_val = (x);				\
	__chk_user_ptr(__rpu_ptr);					\
									\
	uaccess_ttbr0_enable();						\
	__raw_put_mem("sttr", __rpu_val, __rpu_ptr, err, U);		\
	uaccess_ttbr0_disable();					\
} while (0)
```

### [`__raw_put_mem()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L284)

ã‚µã‚¤ã‚ºã®å¤§ãã•ã«å¿œã˜ãŸã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’å‘¼ã³å‡ºã™ã€‚

```c
#define __raw_put_mem(str, x, ptr, err, type)					\
do {										\
	__typeof__(*(ptr)) __pu_val = (x);					\
	switch (sizeof(*(ptr))) {						\
	case 1:									\
		__put_mem_asm(str "b", "%w", __pu_val, (ptr), (err), type);	\
		break;								\
	case 2:									\
		__put_mem_asm(str "h", "%w", __pu_val, (ptr), (err), type);	\
		break;								\
	case 4:									\
		__put_mem_asm(str, "%w", __pu_val, (ptr), (err), type);		\
		break;								\
	case 8:									\
		__put_mem_asm(str, "%x", __pu_val, (ptr), (err), type);		\
		break;								\
	default:								\
		BUILD_BUG();							\
	}									\
} while (0)
```

### [`__put_mem_asm()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L276)

```c
#define __put_mem_asm(store, reg, x, addr, err, type)			\
	asm volatile(							\
	"1:	" store "	" reg "1, [%2]\n"			\
	"2:\n"								\
	_ASM_EXTABLE_##type##ACCESS_ERR(1b, 2b, %w0)			\
	: "+r" (err)							\
	: "rZ" (x), "r" (addr))
```


## [`get_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L254)

åŸºæœ¬çš„ã«ã¯ `put_user()` ã¨åŒã˜æ„Ÿã˜ã€‚

```c
#define get_user	__get_user
```

### [`__get_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L247)

```c
#define __get_user(x, ptr)						\
({									\
	int __gu_err = 0;						\
	__get_user_error((x), (ptr), __gu_err);				\
	__gu_err;							\
})
```

### [`__get_user_error()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L235)

```c
#define __get_user_error(x, ptr, err)					\
do {									\
	__typeof__(*(ptr)) __user *__p = (ptr);				\
	might_fault();							\
	if (access_ok(__p, sizeof(*__p))) {				\
		__p = uaccess_mask_ptr(__p);				\
		__raw_get_user((x), __p, (err));			\
	} else {							\
		(x) = (__force __typeof__(x))0; (err) = -EFAULT;	\
	}								\
} while (0)
```

### [`__raw_get_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L222)

```c
/*
 * We must not call into the scheduler between uaccess_ttbr0_enable() and
 * uaccess_ttbr0_disable(). As `x` and `ptr` could contain blocking functions,
 * we must evaluate these outside of the critical section.
 */
#define __raw_get_user(x, ptr, err)					\
do {									\
	__typeof__(*(ptr)) __user *__rgu_ptr = (ptr);			\
	__typeof__(x) __rgu_val;					\
	__chk_user_ptr(ptr);						\
									\
	uaccess_ttbr0_enable();						\
	__raw_get_mem("ldtr", __rgu_val, __rgu_ptr, err, U);		\
	uaccess_ttbr0_disable();					\
									\
	(x) = __rgu_val;						\
} while (0)
```

### [`__raw_get_mem()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L195)

```c
#define __raw_get_mem(ldr, x, ptr, err, type)					\
do {										\
	unsigned long __gu_val;							\
	switch (sizeof(*(ptr))) {						\
	case 1:									\
		__get_mem_asm(ldr "b", "%w", __gu_val, (ptr), (err), type);	\
		break;								\
	case 2:									\
		__get_mem_asm(ldr "h", "%w", __gu_val, (ptr), (err), type);	\
		break;								\
	case 4:									\
		__get_mem_asm(ldr, "%w", __gu_val, (ptr), (err), type);		\
		break;								\
	case 8:									\
		__get_mem_asm(ldr, "%x",  __gu_val, (ptr), (err), type);	\
		break;								\
	default:								\
		BUILD_BUG();							\
	}									\
	(x) = (__force __typeof__(*(ptr)))__gu_val;				\
} while (0)
```

### [`__get_mem_asm()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L187)

```c
/*
 * The "__xxx" versions of the user access functions do not verify the address
 * space - it must have been done previously with a separate "access_ok()"
 * call.
 *
 * The "__xxx_error" versions set the third argument to -EFAULT if an error
 * occurs, and leave it unchanged on success.
 */
#define __get_mem_asm(load, reg, x, addr, err, type)			\
	asm volatile(							\
	"1:	" load "	" reg "1, [%2]\n"			\
	"2:\n"								\
	_ASM_EXTABLE_##type##ACCESS_ERR_ZERO(1b, 2b, %w0, %w1)		\
	: "+r" (err), "=r" (x)						\
	: "r" (addr))
```


## `copy_to_user()`

`copy_to_user()` ã¨ `_copy_to_user()` ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¾å­˜ã—ãªã„éƒ¨åˆ†ã€‚
`raw_copy_to_user()` ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¾å­˜ã€‚

### [`raw_copy_to_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L374)

```c
#define raw_copy_to_user(to, from, n)					\
({									\
	unsigned long __actu_ret;					\
	uaccess_ttbr0_enable();						\
	__actu_ret = __arch_copy_to_user(__uaccess_mask_ptr(to),	\
				    (from), (n));			\
	uaccess_ttbr0_disable();					\
	__actu_ret;							\
})
```

### [`__arch_copy_to_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/lib/copy_to_user.S#L56)

ã¡ã‚‡ã£ã¨ã“ã®è¾ºã®ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’å…¨éƒ¨è¿½ã†å…ƒæ°—ãŒæ®‹ã£ã¦ãªã„ã€‚

```c
end	.req	x5
srcin	.req	x15
SYM_FUNC_START(__arch_copy_to_user)
	add	end, x0, x2
	mov	srcin, x1
#include "copy_template.S"
	mov	x0, #0
	ret

	// Exception fixups
9997:	cmp	dst, dstin
	b.ne	9998f
	// Before being absolutely sure we couldn't copy anything, try harder
	ldrb	tmp1w, [srcin]
USER(9998f, sttrb tmp1w, [dst])
	add	dst, dst, #1
9998:	sub	x0, end, dst			// bytes not copied
	ret
SYM_FUNC_END(__arch_copy_to_user)
EXPORT_SYMBOL(__arch_copy_to_user)
```

### [`copy_template.S`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/lib/copy_template.S)

åŒæ§˜ã«ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’å…¨éƒ¨è¿½ã†å…ƒæ°—ãŒæ®‹ã£ã¦ãªã„ã€‚
ãŸã ã€æ„å›³ã—ã¦ã‚‹æ“ä½œã¯ã‚³ãƒ¡ãƒ³ãƒˆã«ã‚ã‚‹é€šã‚Šã€‚

```c
/*
 * Copy a buffer from src to dest (alignment handled by the hardware)
 *
 * Parameters:
 *	x0 - dest
 *	x1 - src
 *	x2 - n
 * Returns:
 *	x0 - dest
 */
```


## `copy_from_user()`

`copy_from_user()` ã¨ `_copy_from_user()` ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¾å­˜ã—ãªã„éƒ¨åˆ†ã€‚
`raw_copy_from_user()` ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¾å­˜ã€‚

### [`raw_copy_from_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/include/asm/uaccess.h#L363)

```c
extern unsigned long __must_check __arch_copy_from_user(void *to, const void __user *from, unsigned long n);
#define raw_copy_from_user(to, from, n)					\
({									\
	unsigned long __acfu_ret;					\
	uaccess_ttbr0_enable();						\
	__acfu_ret = __arch_copy_from_user((to),			\
				      __uaccess_mask_ptr(from), (n));	\
	uaccess_ttbr0_disable();					\
	__acfu_ret;							\
})
```

### [`__arch_copy_from_user()`](https://elixir.bootlin.com/linux/v6.10.1/source/arch/arm64/lib/copy_from_user.S#L57)

```c
end	.req	x5
srcin	.req	x15
SYM_FUNC_START(__arch_copy_from_user)
	add	end, x0, x2
	mov	srcin, x1
#include "copy_template.S"
	mov	x0, #0				// Nothing to copy
	ret

	// Exception fixups
9997:	cmp	dst, dstin
	b.ne	9998f
	// Before being absolutely sure we couldn't copy anything, try harder
USER(9998f, ldtrb tmp1w, [srcin])
	strb	tmp1w, [dst], #1
9998:	sub	x0, end, dst			// bytes not copied
	ret
SYM_FUNC_END(__arch_copy_from_user)
EXPORT_SYMBOL(__arch_copy_from_user)
```

